---
title: "Beyond Click Counts: Finding the Right Signals for Good Design"
excerpt: "Click counts are noise. Real design success is measured in signals that show whether people actually achieved what they came to do."
tags: [ux, design, product]
date: 09-03-2025
slug: beyond-click-counts-good-signals-for-design-success
coverImagePublicId: newsletters/beyond-click-counts-good-signals-for-design-success/cover
---

## The Big Idea

Design success is measured in signals that show whether people actually achieved what they came to do.

## Clicks Aren't the Problem

When it comes to design success, clicks aren't the problem - they're just a symptom you'll hear about when people are frustrated.

Last time I argued that [“too many clicks” isn't useful feedback](https://mikebifulco.com/newsletter/stop-counting-clicks).

When something works, people finish tasks, move forward, and feel confident doing their work.

When things aren't working and people are really frustrated, you'll _hear_ about it through the feedback mechanisms you make available to your end users.

There is also a meaningful gap between these two camps: when workflows are merely good enough, people won’t complain, but they also won’t thrive. This silent middle ground is where design stagnates, and where you lose the opportunity to turn reluctant users into superfans.

The opportunity for design teams is to improve user experience by collecting data, feedback, and listening to signals that can help you make your designs better.

So, what is a the right signal that your designs are working?

Here's the catch: **there's no universal checklist.**

What you measure should depend on the purpose of the feature you're building. Clearly defining success metrics and goals will help you decide what signals to measure.

## All Design Leaves Evidence

Good, bad, or otherwise, the output of your design creates signals that you can observe, quantitatively measure, and qualitatively assess in order to improved your feature on its next iteration.

A signup form, a payroll system, and a paint-color selector each have different definitions of success. You can't copy-paste metrics across projects. What matters is asking, up front: what does success look like here?

If your goal is to get high-intent leads to convert to sales, you'll likely want to measure dropoff at each step of your funnel. Make changes to your design to improve the conversion rate at each step, **and** iterate based on what you measure.

Maybe you're designing for a scenario where accuracy is paramount - like in many mechanical engineering or medical design scenarios. In this case, success might be measured by how many incorrect entries are submitted into your system.

Maybe it's speed. Maybe it's accuracy. Maybe it's trust. Whatever it is, define it clearly. Once you do, your metrics stop being vanity numbers and start being a compass. They help you see if you're heading the right way, or if it's time to adjust course.

Iteration without evidence is just guesswork. Iteration with the right signals is how you build something people actually love to use.

## The Takeaway

Don't count clicks. Decide what success means for _this_ design, then measure and observe the signals that point you toward it, and iterate from there.

---

## More on measuring design success

- While not _directly_ about design, Scott Belsky's [The Messy Middle](https://hardcover.app/books/the-messy-middle) reflects on the challenges of getting through the most ambiguous parts of any project.
- Dan Mall has a great video on [Measuring Quality in Design Systems](https://www.youtube.com/watch?v=FJ2ppNwT6Ts)
- I'm a big fan of (previous Tiny Improvement Sponsor) PostHog because they offer tools to make your product better with a massively generous free tier. Check out their [Complete Guide to Event Tracking](https://posthog.com/tutorials/event-tracking-guide) to see how you can track events and metrics in your product in a snap.
